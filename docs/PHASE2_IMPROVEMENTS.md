# üöÄ Phase 2 Improvements - Detail Extractor Enhancements

**Estado**: üìã Planificado
**Prioridad**: Alta (despu√©s de migraci√≥n b√°sica a PostgreSQL)
**Fecha**: 2025-11-07

---

## üéØ Objetivo

Mejorar `phase2_detail_extractor.py` con optimizaciones de rendimiento, deduplicaci√≥n, y gesti√≥n inteligente de media seg√∫n la fuente.

---

## üìã Requirements del Usuario

### 1. **NO Descargar Im√°genes** üö´üñºÔ∏è

**Raz√≥n**: Las im√°genes no son necesarias para el prop√≥sito del sistema, solo ocupan espacio en disco.

**Implementaci√≥n**:
```python
# EN: phase2_detail_extractor.py
# Comentar o eliminar c√≥digo de descarga de im√°genes
# Solo guardar URLs de im√°genes en la base de datos

# ANTES:
download_image(url, path)

# DESPU√âS:
# Solo guardar URL, no descargar
post_data['images'] = [{'url': url, 'downloaded': False}]
```

**Beneficios**:
- ‚úÖ Ahorro de espacio en disco
- ‚úÖ Scraping m√°s r√°pido
- ‚úÖ Menor ancho de banda

---

### 2. **Deduplicaci√≥n de Media** üîÑ

**Problema**: Si un post se reprocesa, los archivos (videos, audios) se descargan de nuevo, duplicando en disco.

**Soluci√≥n**: Usar tabla `media_files` con hash SHA256 (ya existe en schema_v2.sql)

**Flujo**:
```python
# 1. Calcular hash del archivo antes/despu√©s de descargar
file_hash = hashlib.sha256(file_content).hexdigest()

# 2. Verificar si ya existe en media_files
existing = session.execute(text("""
    SELECT file_path FROM media_files WHERE file_hash = :hash
"""), {"hash": file_hash}).fetchone()

if existing:
    # Usar archivo existente
    file_path = existing[0]
    logger.info(f"‚úì Media already exists: {file_path}")
else:
    # Descargar nuevo
    file_path = download_and_save(url)
    # Insertar en media_files
    session.execute(text("""
        INSERT INTO media_files (file_hash, file_path, file_type, file_size)
        VALUES (:hash, :path, :type, :size)
    """), {...})
```

**Tabla media_files** (ya en schema_v2.sql):
```sql
CREATE TABLE media_files (
    id SERIAL PRIMARY KEY,
    file_hash VARCHAR(64) UNIQUE NOT NULL,  -- SHA256
    file_path TEXT NOT NULL,
    file_size BIGINT,
    reference_count INTEGER DEFAULT 0,
    ...
)
```

**Beneficios**:
- ‚úÖ No duplicar archivos
- ‚úÖ Ahorrar espacio (un video puede aparecer en m√∫ltiples posts)
- ‚úÖ Tracking de referencias

---

### 3. **Settings para Videos de Patreon** ‚öôÔ∏è

**Requirement**: Permitir configurar si videos de Patreon se descargan o solo se indica "ver en Patreon".

**Opciones**:

#### Opci√≥n A: Descargar (comportamiento actual)
```python
if settings['patreon']['download_videos']:
    video_path = download_patreon_video(url)
    post_data['video_file'] = video_path
```

#### Opci√≥n B: Solo indicar "ver en Patreon"
```python
else:
    post_data['video_url'] = url
    post_data['video_note'] = "Ver en Patreon"
    post_data['requires_patreon'] = True
```

**Configuraci√≥n** (`config/settings.json`):
```json
{
  "media": {
    "patreon": {
      "download_videos": true,      // true = descargar, false = solo URL
      "download_audios": true,
      "download_images": false       // Ya NO descargar
    },
    "youtube": {
      "mode": "embed",               // "embed" o "download"
      "download_subtitles": true,
      "subtitle_languages": ["en", "es"]
    }
  }
}
```

**Implementaci√≥n**:
```python
# Cargar settings
with open('config/settings.json') as f:
    settings = json.load(f)

# Aplicar seg√∫n configuraci√≥n
if post_source == 'patreon':
    if settings['media']['patreon']['download_videos']:
        # Descargar
        pass
    else:
        # Solo URL
        pass
```

---

### 4. **YouTube Videos - Dual Mode** üé•

**Requirement**: Soportar 2 modos para videos de YouTube seg√∫n configuraci√≥n.

#### **Modo A: Embed** (Simple, recomendado)
```python
if settings['media']['youtube']['mode'] == 'embed':
    post_data['youtube_embed'] = {
        'video_id': extract_youtube_id(url),
        'url': url,
        'embed_html': f'<iframe src="https://youtube.com/embed/{video_id}"></iframe>'
    }
```

**Ventajas**:
- ‚úÖ Instant√°neo (no descarga)
- ‚úÖ Siempre disponible
- ‚úÖ No ocupa espacio
- ‚úÖ Subt√≠tulos nativos de YouTube

**Desventajas**:
- ‚ùå Requiere conexi√≥n a internet
- ‚ùå YouTube puede borrar el video

#### **Modo B: Download con yt-dlp** (Complejo, para archivos)
```python
elif settings['media']['youtube']['mode'] == 'download':
    try:
        result = download_youtube_video(
            url,
            subtitles=['en', 'es'],
            quality='best'
        )
        post_data['video_file'] = result['video_path']
        post_data['subtitles'] = result['subtitles']  # {en: path, es: path}
    except DownloadError as e:
        # Si falla, enviar a cola de reintentos
        enqueue_youtube_download(url, post_id)
        post_data['video_status'] = 'queued'
```

**Ventajas**:
- ‚úÖ Archivo local (permanente)
- ‚úÖ Subt√≠tulos descargados (English + Spanish)
- ‚úÖ Funciona sin internet

**Desventajas**:
- ‚ùå Lento (puede tardar minutos)
- ‚ùå Ocupa espacio (videos grandes)
- ‚ùå Puede fallar (video privado, borrado, etc.)

**Dependencia**:
```bash
pip install yt-dlp
```

**C√≥digo ejemplo**:
```python
import yt_dlp

def download_youtube_video(url, subtitles=['en', 'es'], quality='best'):
    """Download YouTube video with subtitles"""

    ydl_opts = {
        'format': quality,
        'outtmpl': 'media/youtube/%(id)s.%(ext)s',
        'writesubtitles': True,
        'subtitleslangs': subtitles,
        'writeautomaticsub': True,  # Fallback to auto-generated
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=True)

        return {
            'video_path': ydl.prepare_filename(info),
            'subtitles': {
                'en': f"media/youtube/{info['id']}.en.vtt",
                'es': f"media/youtube/{info['id']}.es.vtt"
            },
            'metadata': {
                'title': info['title'],
                'duration': info['duration'],
                'uploader': info['uploader']
            }
        }
```

---

### 5. **Sistema de Colas con Celery** üîÑ‚è∞

**Problema**: Operaciones lentas (descargas, scraping) bloquean el script principal.

**Soluci√≥n**: Implementar Celery para operaciones as√≠ncronas.

#### **Qu√© deber√≠a ir a cola**:

1. **Phase 1: URL Collection**
   - Scraping de p√°ginas de creator (puede tardar minutos)
   - Reintentos si falla

2. **Phase 2: Detail Extraction**
   - Descargas de videos (Patreon, YouTube)
   - Descargas de audios
   - Transcripciones (Whisper API puede tardar)
   - Reintentos si falla

3. **Phase 3: Collections**
   - Scraping de collections (m√∫ltiples p√°ginas)
   - Asociar posts a collections

#### **Arquitectura propuesta**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Main Script    ‚îÇ
‚îÇ  (Orchestrator) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ             ‚îÇ
         v             v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Celery Task ‚îÇ  ‚îÇ Celery Task  ‚îÇ
‚îÇ Phase 1     ‚îÇ  ‚îÇ Phase 2      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                ‚îÇ
       v                v
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL Database     ‚îÇ
‚îÇ   (scraping_status)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **Implementaci√≥n**:

**1. Definir tasks** (`src/celery_tasks.py`):
```python
from celery import Celery

app = Celery('patreon_scraper', broker='redis://localhost:6379/0')

@app.task(bind=True, max_retries=3)
def scrape_post_details(self, post_id, post_url):
    """Task: Extract post details"""
    try:
        # Scraping logic
        details = extract_post_details(post_url)

        # Save to database
        tracker = PostgresTracker()
        tracker.mark_details_extracted(post_id, success=True)

        return {'status': 'success', 'post_id': post_id}

    except Exception as e:
        # Retry with exponential backoff
        self.retry(exc=e, countdown=60 * (2 ** self.request.retries))

@app.task(bind=True, max_retries=5)
def download_youtube_video_task(self, url, post_id):
    """Task: Download YouTube video with retries"""
    try:
        result = download_youtube_video(url)
        # Update database
        return result
    except Exception as e:
        self.retry(exc=e, countdown=300)  # 5 min retry
```

**2. Encolar tareas**:
```python
# EN: orchestrator.py o phase2_detail_extractor.py

from celery_tasks import scrape_post_details, download_youtube_video_task

# Encolar Phase 2 para todos los posts pendientes
for post in posts_needing_details:
    scrape_post_details.delay(post['post_id'], post['post_url'])

# Encolar descarga de YouTube
download_youtube_video_task.delay(youtube_url, post_id)
```

**3. Iniciar workers**:
```bash
# Terminal 1: Worker para Phase 1
celery -A celery_tasks worker --queue=phase1 -c 2

# Terminal 2: Worker para Phase 2 (descargas)
celery -A celery_tasks worker --queue=phase2 -c 1

# Terminal 3: Worker para Phase 3
celery -A celery_tasks worker --queue=phase3 -c 2
```

**Beneficios**:
- ‚úÖ No bloqueante (contin√∫a procesando otros posts)
- ‚úÖ Reintentos autom√°ticos si falla
- ‚úÖ Paralelizaci√≥n (m√∫ltiples workers)
- ‚úÖ Monitoreo con Flower (`celery flower`)

**‚ö†Ô∏è NOTA**: Sistema de colas NO est√° implementado actualmente. Es una mejora futura.

---

## üìä Orden de Implementaci√≥n

### **Paso 1: Migraci√≥n B√°sica** (AHORA)
- [x] Crear PostgresTracker
- [ ] Migrar phase1/2/3 a PostgreSQL
- [ ] Probar que funciona b√°sicamente

### **Paso 2: Optimizaciones de Media** (SIGUIENTE)
1. [ ] Deshabilitar descarga de im√°genes
2. [ ] Implementar deduplicaci√≥n con media_files table
3. [ ] Crear config/settings.json con opciones de media

### **Paso 3: YouTube Support** (DESPU√âS)
1. [ ] Implementar modo "embed" (simple)
2. [ ] Implementar modo "download" con yt-dlp
3. [ ] Descargar subt√≠tulos (en, es)

### **Paso 4: Sistema de Colas** (FUTURO)
1. [ ] Setup Celery + Redis
2. [ ] Crear celery_tasks.py con tasks
3. [ ] Migrar operaciones lentas a tasks
4. [ ] Configurar workers y monitoring

---

## üéõÔ∏è Configuraci√≥n Propuesta

**Archivo**: `config/settings.json`

```json
{
  "media": {
    "images": {
      "download": false,
      "store_urls": true
    },
    "patreon": {
      "videos": {
        "download": true,
        "quality": "best",
        "format": "mp4"
      },
      "audios": {
        "download": true,
        "format": "mp3"
      }
    },
    "youtube": {
      "mode": "embed",
      "download_if_embed_fails": false,
      "download_settings": {
        "quality": "best",
        "subtitles": ["en", "es"],
        "auto_subtitles": true
      }
    },
    "deduplication": {
      "enabled": true,
      "hash_algorithm": "sha256"
    }
  },
  "celery": {
    "enabled": false,
    "broker": "redis://localhost:6379/0",
    "workers": {
      "phase1": 2,
      "phase2": 1,
      "phase3": 2
    }
  },
  "scraping": {
    "max_retries": 3,
    "retry_delay": 60,
    "timeout": 300
  }
}
```

---

## ‚úÖ Validaci√≥n del Plan por Usuario

Usuario confirma:
> "vale cuando abordemos el migrado de phase2 una vez que funcione bien con bbdd hay que mejorarlo"

‚úÖ **Correcto**: Primero migrar, luego mejorar

> "Que no se descargen imagenes no son necesaria"

‚úÖ **Implementar**: Deshabilitar descarga de im√°genes

> "que no se dupliquen en disco si procesa de nuevo el post"

‚úÖ **Implementar**: Deduplicaci√≥n con media_files + SHA256

> "me gustaria en settings poder decir para patreon, si el video es de patreon si se descarga o se comenta que hay que verlo en patreon"

‚úÖ **Implementar**: Config patreon.videos.download (true/false)

> "para los de youtube si se coge el enlace y se embembe en el post o se descarga el youtube con los dos subitulos english and spanish"

‚úÖ **Implementar**: youtube.mode ("embed" o "download") + subtitles [en, es]

> "si no se pueden desrcargar deberia ir lal sistema de colas"

‚úÖ **Implementar**: Celery tasks para descargas con reintentos

> "incluso la parte inicial de fase 1 y la de fase 3 deberian ir mediante la cola"

‚úÖ **Implementar**: Celery para Phase 1, 2, y 3

> "corrigeme si voy mal"

‚úÖ **RESPUESTA**: ¬°Vas perfecto! El plan es s√≥lido y arquitect√≥nicamente correcto.

---

## üìù Notas Finales

- **Prioridad 1**: Migraci√≥n b√°sica a PostgreSQL (funcional)
- **Prioridad 2**: Optimizaciones de media (no im√°genes, deduplicaci√≥n)
- **Prioridad 3**: YouTube support (embed + download)
- **Prioridad 4**: Sistema de colas (Celery)

**Tiempo estimado**:
- Migraci√≥n b√°sica: 4-6 horas
- Optimizaciones media: 3-4 horas
- YouTube support: 4-5 horas
- Sistema de colas: 8-10 horas

**Total**: ~20-25 horas para Phase 2 completa con todas las mejoras

---

**Creado**: 2025-11-07
**Aprobado por**: Usuario
**Estado**: Pendiente de implementaci√≥n (despu√©s de migraci√≥n b√°sica)
