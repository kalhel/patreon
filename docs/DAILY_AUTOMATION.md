# ‚è∞ Automatizaci√≥n Diaria - Patreon Scraper

**Gu√≠a completa para configurar scraping autom√°tico diario**

---

## üéØ Objetivo

Configurar el sistema para que autom√°ticamente:
1. **Detecte** posts nuevos cada d√≠a
2. **Scrape** solo el contenido nuevo (no reprocesa existentes)
3. **Descargue** media de posts nuevos
4. **Genere** tags con IA
5. **Suba** a Notion autom√°ticamente

---

## ‚ú® Sistema de Scraping Incremental

### C√≥mo Funciona

El sistema mantiene un **archivo de estado** (`data/state/{creator}_state.json`) para cada creador que incluye:

```json
{
  "creator_id": "headonhistory",
  "last_scrape": "2025-11-01T10:30:00",
  "processed_post_ids": ["123456", "123455", "123454", ...],
  "total_posts": 150,
  "last_post_date": "2024-10-30"
}
```

### Ventajas

- ‚úÖ **No reprocesa**: Solo scrape posts nuevos
- ‚úÖ **R√°pido**: No necesita scrollear todo el hist√≥rico
- ‚úÖ **Seguro**: Mantiene posts existentes intactos
- ‚úÖ **Merge autom√°tico**: Combina nuevos con existentes
- ‚úÖ **Estad√≠sticas**: Tracking de √∫ltima ejecuci√≥n

---

## üöÄ Uso Manual del Scraper Incremental

### Comandos B√°sicos

```bash
# Ver estad√≠sticas (cu√°ndo fue √∫ltimo scrape)
python src/incremental_scraper.py --stats

# Scrape incremental de todos los creadores (solo nuevos)
python src/incremental_scraper.py --scrape-all

# Scrape incremental con detalles completos
python src/incremental_scraper.py --scrape-all --full-details

# Scrape incremental de un solo creador
python src/incremental_scraper.py --creator headonhistory --full-details

# Reset state (forzar rescrape completo)
python src/incremental_scraper.py --reset headonhistory
```

### Ejemplo de Salida

```
============================================================
INCREMENTAL SCRAPE: headonhistory
============================================================

üìä Previously processed: 150 posts
üïê Last scrape: 2025-11-01T10:30:00

üîç Scanning for new posts...
  ‚ú® NEW: New Post Title Here
  ‚ú® NEW: Another New Post

üìà Found 2 new posts
üìã Kept 150 existing posts

üìÑ Scraping full details for 2 new posts...
  [1/2] New Post Title Here...
  [2/2] Another New Post...

üíæ Saved state: 152 posts tracked

‚úÖ Incremental scrape complete:
   ‚ú® New posts: 2
   üìã Existing posts: 150
   üìä Total posts: 152
```

---

## ü§ñ Script de Automatizaci√≥n Diaria

### El Script: `daily_scrape.sh`

Script bash que ejecuta el pipeline completo:

```bash
./daily_scrape.sh [opciones]
```

### Opciones Disponibles

| Opci√≥n | Descripci√≥n |
|--------|-------------|
| `--full-details` | Scrape detalles completos de posts nuevos |
| `--with-media` | Descargar media despu√©s de scrapear |
| `--with-tags` | Generar tags con IA |
| `--with-notion` | Subir a Notion |
| `--all` | Hacer todo (equivale a todas las opciones anteriores) |

### Ejemplos de Uso

```bash
# Solo scrape r√°pido (metadata b√°sica)
./daily_scrape.sh

# Scrape completo con detalles
./daily_scrape.sh --full-details

# Pipeline completo
./daily_scrape.sh --all

# Solo scrape y media (sin tags ni notion)
./daily_scrape.sh --full-details --with-media
```

### Variables de Entorno Necesarias

```bash
# Para generaci√≥n de tags
export GEMINI_API_KEY="tu-gemini-api-key"

# Para subida a Notion
export NOTION_API_KEY="tu-notion-api-key"
```

---

## ‚è∞ Configuraci√≥n de Cron (Ejecuci√≥n Diaria Autom√°tica)

### Paso 1: Crear Script de Entorno

Primero crea un script que configure las variables de entorno:

```bash
# Crear archivo de entorno
nano /home/javif/proyectos/astrologia/patreon/.env
```

Contenido del archivo `.env`:

```bash
#!/bin/bash
# Environment variables for Patreon Scraper

export GEMINI_API_KEY="tu-gemini-api-key-aqui"
export NOTION_API_KEY="tu-notion-api-key-aqui"
export PATH="/usr/local/bin:/usr/bin:/bin:$PATH"
```

```bash
# Hacer ejecutable
chmod +x /home/javif/proyectos/astrologia/patreon/.env
```

### Paso 2: Crear Script Wrapper para Cron

Cron necesita rutas absolutas y entorno configurado:

```bash
# Crear wrapper
nano /home/javif/proyectos/astrologia/patreon/cron_daily_scrape.sh
```

Contenido:

```bash
#!/bin/bash
# Wrapper for cron execution

# Load environment variables
source /home/javif/proyectos/astrologia/patreon/.env

# Change to project directory
cd /home/javif/proyectos/astrologia/patreon

# Run daily scrape
/home/javif/proyectos/astrologia/patreon/daily_scrape.sh --all

# Exit with status
exit $?
```

```bash
# Hacer ejecutable
chmod +x /home/javif/proyectos/astrologia/patreon/cron_daily_scrape.sh
```

### Paso 3: Configurar Cron

```bash
# Editar crontab
crontab -e
```

A√±ade una de estas l√≠neas:

```bash
# Opci√≥n 1: Diario a las 3 AM (recomendado)
0 3 * * * /home/javif/proyectos/astrologia/patreon/cron_daily_scrape.sh >> /home/javif/proyectos/astrologia/patreon/logs/cron.log 2>&1

# Opci√≥n 2: Diario a las 8 AM
0 8 * * * /home/javif/proyectos/astrologia/patreon/cron_daily_scrape.sh >> /home/javif/proyectos/astrologia/patreon/logs/cron.log 2>&1

# Opci√≥n 3: Dos veces al d√≠a (8 AM y 8 PM)
0 8,20 * * * /home/javif/proyectos/astrologia/patreon/cron_daily_scrape.sh >> /home/javif/proyectos/astrologia/patreon/logs/cron.log 2>&1

# Opci√≥n 4: Cada 6 horas
0 */6 * * * /home/javif/proyectos/astrologia/patreon/cron_daily_scrape.sh >> /home/javif/proyectos/astrologia/patreon/logs/cron.log 2>&1
```

### Explicaci√≥n del Formato Cron

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ minuto (0 - 59)
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ hora (0 - 23)
‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ d√≠a del mes (1 - 31)
‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ mes (1 - 12)
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ d√≠a de la semana (0 - 6) (Domingo=0)
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ
* * * * * comando a ejecutar
```

Ejemplos:
- `0 3 * * *` - Diario a las 3:00 AM
- `0 */6 * * *` - Cada 6 horas
- `0 8,20 * * *` - A las 8 AM y 8 PM
- `0 9 * * 1` - Lunes a las 9 AM

### Paso 4: Verificar Cron

```bash
# Ver crontab actual
crontab -l

# Ver log del sistema de cron
grep CRON /var/log/syslog | tail -20

# Ver log de tu script
tail -f /home/javif/proyectos/astrologia/patreon/logs/cron.log
```

### Paso 5: Probar Manualmente

Antes de confiar en cron, prueba manualmente:

```bash
# Test del wrapper
/home/javif/proyectos/astrologia/patreon/cron_daily_scrape.sh

# Ver el log generado
cat /home/javif/proyectos/astrologia/patreon/logs/cron.log
```

---

## üìä Monitoreo y Logs

### Archivos de Log

El sistema genera m√∫ltiples logs:

```
logs/
‚îú‚îÄ‚îÄ cron.log                           ‚Üê Log de ejecuciones cron
‚îú‚îÄ‚îÄ daily_scrape_20251101_030000.log  ‚Üê Log de cada ejecuci√≥n diaria
‚îú‚îÄ‚îÄ incremental_scraper.log           ‚Üê Log del scraper incremental
‚îú‚îÄ‚îÄ main.log                          ‚Üê Log general
‚îú‚îÄ‚îÄ media_downloader.log              ‚Üê Log de descargas
‚îú‚îÄ‚îÄ tag_generator.log                 ‚Üê Log de generaci√≥n de tags
‚îî‚îÄ‚îÄ notion_integrator.log             ‚Üê Log de subida a Notion
```

### Ver Logs en Tiempo Real

```bash
# Log del cron
tail -f logs/cron.log

# Log del scraper incremental
tail -f logs/incremental_scraper.log

# Todos los logs
tail -f logs/*.log
```

### Ver Estad√≠sticas

```bash
# Ver estado de cada creador
python src/incremental_scraper.py --stats

# Ver res√∫menes de scrapes
ls -lh data/state/scrape_summary_*.json
cat data/state/scrape_summary_latest.json
```

---

## üîî Notificaciones (Opcional)

### Opci√≥n 1: Notificaciones del Sistema (Linux Desktop)

Edita `daily_scrape.sh` y descomenta:

```bash
# Al final del script
notify-send "Patreon Scraper" "Found $NEW_POSTS new posts"
```

### Opci√≥n 2: Email

A√±ade al final de `cron_daily_scrape.sh`:

```bash
# Enviar email si hay posts nuevos
if [ "$NEW_POSTS" -gt 0 ]; then
    echo "Found $NEW_POSTS new Patreon posts" | mail -s "Patreon Update" tu@email.com
fi
```

### Opci√≥n 3: Telegram Bot (Avanzado)

Crea un script separado:

```bash
# notify_telegram.sh
#!/bin/bash
BOT_TOKEN="tu-bot-token"
CHAT_ID="tu-chat-id"
MESSAGE="$1"

curl -s -X POST "https://api.telegram.org/bot$BOT_TOKEN/sendMessage" \
    -d chat_id="$CHAT_ID" \
    -d text="$MESSAGE"
```

Ll√°malo desde `daily_scrape.sh`:

```bash
./notify_telegram.sh "Found $NEW_POSTS new Patreon posts!"
```

---

## üîß Troubleshooting

### Cron no se ejecuta

**Problema**: El cron no parece ejecutarse

**Soluciones**:
1. Verificar que el servicio cron est√° corriendo:
   ```bash
   sudo systemctl status cron
   ```

2. Verificar errores en syslog:
   ```bash
   grep CRON /var/log/syslog | tail
   ```

3. Verificar permisos:
   ```bash
   ls -l /home/javif/proyectos/astrologia/patreon/*.sh
   ```

### Variables de entorno no funcionan

**Problema**: El script no puede acceder a API keys

**Soluci√≥n**: Verificar que `.env` se est√° cargando correctamente:

```bash
# A√±adir debug al wrapper
echo "GEMINI_API_KEY: ${GEMINI_API_KEY:0:10}..." >> /tmp/cron_debug.log
echo "NOTION_API_KEY: ${NOTION_API_KEY:0:10}..." >> /tmp/cron_debug.log
```

### Browser no se inicia (headless)

**Problema**: ChromeDriver falla en modo headless

**Soluci√≥n**: Verificar que Chrome est√° instalado y es compatible:

```bash
google-chrome --version
chromedriver --version
```

### Cookies expiran

**Problema**: Las cookies expiran antes del scrape

**Soluci√≥n**: Re-autenticarse manualmente:

```bash
cd /home/javif/proyectos/astrologia/patreon
source venv/bin/activate
python src/main.py --auth-only
```

---

## üìà Flujo de Trabajo Recomendado

### Configuraci√≥n Inicial (Una Vez)

```bash
# 1. Scrape completo inicial
python src/main.py --scrape-all --full-details

# 2. Descargar toda la media
python src/media_downloader.py --all

# 3. Generar tags
python src/tag_generator.py --all

# 4. Subir a Notion
python src/notion_integrator.py --all

# 5. Configurar cron para ejecuciones diarias
crontab -e  # A√±adir l√≠nea de cron
```

### Ejecuci√≥n Diaria Autom√°tica

El cron ejecutar√°:

```bash
./daily_scrape.sh --all
```

Que har√°:
1. ‚úÖ Scrape incremental (solo nuevos posts)
2. ‚úÖ Download media (solo de posts nuevos)
3. ‚úÖ Generate tags (solo posts nuevos)
4. ‚úÖ Upload to Notion (solo posts nuevos)

### Mantenimiento Mensual

```bash
# Verificar estado
python src/incremental_scraper.py --stats

# Verificar logs
tail -100 logs/cron.log

# Re-autenticarse (cookies expiran ~1 mes)
python src/main.py --auth-only
```

---

## üí° Tips y Mejores Pr√°cticas

### 1. Empezar Conservador

Comienza con scraping simple y ve a√±adiendo funcionalidad:

```bash
# Semana 1: Solo scrape
0 3 * * * .../daily_scrape.sh

# Semana 2: Scrape + media
0 3 * * * .../daily_scrape.sh --with-media

# Semana 3: Pipeline completo
0 3 * * * .../daily_scrape.sh --all
```

### 2. Horario √ìptimo

- **3 AM** - Ideal, poco tr√°fico en Patreon
- **8 AM** - Antes de empezar el d√≠a
- **Evitar** - Horas pico (12-2 PM, 7-9 PM)

### 3. Backup Regular

```bash
# A√±adir al crontab
0 2 * * 0 tar -czf /backups/patreon_$(date +\%Y\%m\%d).tar.gz /home/javif/proyectos/astrologia/patreon/data
```

### 4. Monitorear Espacio en Disco

```bash
# Verificar espacio usado
du -sh /home/javif/proyectos/astrologia/patreon/data/*

# Limpiar logs antiguos (m√°s de 30 d√≠as)
find logs/ -name "*.log" -mtime +30 -delete
```

---

## ‚úÖ Checklist de Configuraci√≥n

- [ ] Script `daily_scrape.sh` es ejecutable
- [ ] Archivo `.env` creado con API keys
- [ ] Script wrapper `cron_daily_scrape.sh` creado y ejecutable
- [ ] Crontab configurado
- [ ] Test manual del wrapper exitoso
- [ ] Logs directory tiene permisos correctos
- [ ] Variables de entorno funcionan
- [ ] Primera ejecuci√≥n autom√°tica verificada

---

**¬°Con esto tendr√°s un sistema completamente automatizado que scrape Patreon diariamente sin intervenci√≥n manual!** üöÄ‚è∞
